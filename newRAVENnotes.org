* diary

** 8/2/2021

- question of 96k samplerate (to test) and decimation/up conversion 
- LPC seems to be working in lpcforlap.c

** 4/2/2021

TODO: 

ADC example, wavetables for 48k, how to improve vocoder? what is size
of buffer -> filteri warps ? 60 samples (was 96 before so 1 millisecond
fillbuffer), wav read/write for laptop test code and Makefiule

- question if we want to norm buffered DAC to x,y,z (any) if these need
an animated signal for example for Mindlin or for movement through
wavetable - active only in certain modes (knob would then be on seperate ADC for more versatility)

** 3/2/2021

- Codec now working on H743 

- Try vocoder code=TESTED but a bit dull - remade filter coeffss for
  48k - what is IR_SIZE in filter_my.py = impulse response size in
  samples try to reduce this to 1024

check delays etc in warps code for 96k = 96k has delay (check how this delay thing works)

- how to remake wavetables for 48k - depends on type:

/root/projects/ERD_MODULES/RAVEN/older_notes_and_software/docs/temped/py-trm/gnuspeech/Tube: also look into for speech and has some wavetable calcs

- generate crow wavetables (praat?) - we also need sets of crow LPCs - larger windows... what is windowsize again in lpc? *128*

// workflow for inverse filtered wavetables: praat inverse filter, audacity, dump to float using dumpwave.c but we need 32k samplerate -> 48K now

// for drawn wavetable - create tone, isolate sine, redraw with draw tool, save, dump with dumpwave.c

- plan own modes

- movements through wavetables

- basic proof of concept PCB (power H743 and xtals, say 1 or 2 adc in, 2x audio in and 2x audio out with WM8731)

- go through WORM code and see what we can salvage - extract from each voice/approach and also unused elements such as wormaswave

- laptop test basis - makefile and basic output follow worm code

- where we are at with Mindlin and other bird voice code bases, how we can bend and take off from these?

- question in Mindlin of generating and/or using slowly moving forcing functions?

- test simple excitation, eg. tubes and final feedback mix in !

** 27/1/2021

- working through code in finch_void.c from Mindlin in mindlin_auto 
- an we run this in realtime on our platform, how many key parameters - q of x,y,z parameter maps or...
- decouple of source and filter? can we plug different sources into filter and vice vers, is there any back feedback
- what are the series of equations?
- what are the parameters - of course we can vary beta (0 to -4) and amplitude/envelope
- but what are:

aa.gm=24000.; // also mentioned in https://github.com/mschachter/birdy/blob/master/docs/project.pdf as 23500 gamma

in 276286948.pdf in new_docs this is refered to as a time scaling factor - see also Sanz-11.pdf below

aa.r=0.1; 

aa.s1overCH=(360/0.8)*1e08;  // what are these values about?
aa.s1overLB=1.*1e-04; 
aa.s1overLG=(1/82.); 
aa.RB=(.5)*1e07;

 aa.rdis=(300./5.)*(10000.); // 60 0000

CH, LB, LG, RB ? 

looking at: http://lsd.df.uba.ar/papers/PhysRevE.84.Sanz-11.pdf

looks like capacitances, impedances (LB beak?), and RB resistance

trachea is followed by oropharyngeal-esophageal cavity (OEC)

runs at 20x sample rate of 44100

- from mschachter birdy code:

pp->m = 4e-10;
pp->k1 = k1; // var
pp->k2 = 400.0;
pp->beta1 = 444e-7;
pp->beta2 = 4e-11;
pp->c = 16e-3;
pp->f0 = f0; // var
pp->alab = 2e-4;
pp->tau = 5e-6;
pp->a01 = 0.1;
pp->a02 = 0.11;
pp->psub = psub; // var

// x2 is xsquared, x3 cubed as is v

 dstate[0] = v;
 dstate[1] = -pp->k1*x - pp->k2*x3 - pp->beta1*v - pp->beta2*v3 - pp->c*x2*v + pp->f0 + pp->alab*pp->psub*tterm;
 dstate[1] /= pp->m;

// which doesn;t match their description in: https://github.com/mschachter/birdy/blob/master/docs/project.pdf which is more like Mindlin book 7.4 eqn. Q of what is c?

7.4/4.5: y'=-kx + (B-b)y -cx2y

*TODO: try different values an equations with runge-kutta of finch and co*

** 28/2/2021

- finch code: ancho is width and largo is length

- so aa.Ancho1=0.2; aa.Ancho2=.2; aa.Ancho3=0.2;largo1 = 1.5; largo2 =1.5; largo3 = 1.;

which accords with total length of 3.5mm for finch tube/trachea

*for crow/raven we have a length of 70mm and diameter of 7mm (from Fletcher 1988)*

* basics

2 audio ins: 1excitation and 2voice. 1in normed to exc out faked for first modes eg. noise.. where we have no exc but only input

2/voice used for vocoders and LPC only

question of feedback mix back in...

2 audio outs: final out and excitation only out

controls?:

excitation: frequency, volume, mode 

transform: x, y, z?, mode

feedback: amount=mix, delay - mode? like another transform

* TODO

- review what we have in terms of docs and software - what we can also use form WORM - what excitation sources can be seperated.

- basic platform structure with audio.c and process

take from worm - any input process (also vocoder input), generate excitation, apply transformation/vocoder

- start with vocoder from warps, other vocoders
- then Mindlin/Fletcher and other simulations
- overview of basic code and what is working from before
- layout and basic operations - how many knobsADC etc.
- processing plan and flow - how any circular feedback could work?
- question of platform/speed
  
* platform

STM32F767 double precision is our development board.

Smaller STM32F7 is 767VI/VG

left and right audio in to WM8731

Codec is working with test code but has 172.8 MHZ clock (not max of 216) 168 was 405 - will this be fast enough? H743 is 480MHz

TODO:

- ADCs working and any other peripherals (trigger in for example)
- question of samplerate as 48k or 32k? (WORM was 32k, WARPS is 96k!)

** refs

https://wunderkis.de/stm32cube3/index.html

https://longer-vision-robot.gitbook.io/stm32f767zi-full-stack/chapter-2.-programming-for-stm32/2.5-test-on-stm32f767zi-blinky

https://github.com/dpiegdon/STM32F767ZI-Nucleo-144 - altered makefile on x220 for stlink

https://longer-vision-robot.gitbook.io/stm32f767zi-full-stack/chapter-2.-programming-for-stm32/2.5-test-on-stm32f767zi-blinky 
https://github.com/dpiegdon/STM32F767ZI-Nucleo-144  - seems to have usable makefile
Also: https://github.com/bbrown1867/stm32-makefile 

https://community.st.com/s/question/0D53W00000EbURk/stm32f767-cmsis-dsp-keil-error
https://bytefreaks.net/tag/stm32f767
https://gitlab.com/caesar-lab/stm32f7-legacy-library/-/tree/master/Example/f767zi-nucleo/LED_Example

https://www.eevblog.com/forum/projects/stm32-sai-how-to-configure-that-bastard-for-i2s!/ 

Porting this one: [SOLVED] Problem with I2S+DMA on Nucleo H743ZI2 with WM8731 Audio Codec but is for H7 and not our F7 where DMA is different - ABANDON!

https://github.com/df8oe/UHSDR/tree/active-devel/mchf-eclipse/drivers/audio/codec 

SAI: also H7: https://www.cankosar.com/stm32-sai-konfiguration/ 

https://github.com/cankosar/DSP_Target 
https://github.com/cankosar/DSP_Target/blob/master/hw/src/cs4272.cpp 

Or use other audio codecs? WM8994 - but is BGA. CS4272 which is more complex.

What was the smaller 100 pin? STM32F767VI/VG 765 is double precision too H743 also but is big? 144 pin.

ADC: https://skybluetrades.net/stm32-timer-adc-dma-1/ 

https://forum.pjrc.com/archive/index.php/t-53854.html 

* modes

- vocoders
- LPC swoppings, bends, morphs and filters -> where was worm/test code? here in SOFTWARE -> notes on lpc in older notes
- banks of LPC coefficients
- some bends of WORM speech codecs
- various throat simulations, glottal and trachea models
- raven works = physical models
- others

how to swop across modes so eg. use lpc reverse filtered excitation for vocoder

** excitation and filter/transformation

excitation side/filter side with controls for each:

*** exc: 32 modes

controls: frequency + for wavetables select which one, mix of noise with?, amount of feedback/delay length (overrides other settings), elements of simulations, 

- basic input
- processings of basic input eg. inverse filtering, pitch following, other detection for exc changes (noise detection)

// above are input based...

- wavetables - with movement selected (select wavetbale and movement eg. worming): x-select, y-speed, z-movement param

- glottal physical simulations
- original speech synth maybe inv filtered or without LPC filter eg. basic impulsive sources from klatt and co.
- vocoded bands ???
- dry/wet feedback - delayed feedback - this would be extra set of modes like mirrored modes - main mode plus feedback/delay settings
- vosim/others/impulse etc.
- noise mix
- syrinx models - if these are coupled to the transform by reflections eg. any feedback from transforms to take into account.
- peaks-spikes/square wave/simple calcs as in wormed_voice workshop:
- from worm code - excitations used in each of the speech synths: sp0256, klatt, sam, parwave?, tms5200/5100, digitalker, nvp?, votrax

*** transformation: 32 modes

controls: channel vocoder -> , throat/tube ->

- channel vocoder/s - bandpass a la warps (with different sets of bandpasses perhaps eg. follow EMS2000/5000) exc input as exc, voice input as input

warps is third octave (spacings) 48db filters (8 stage?)

- FFT vocoder - spacings, bends?

https://github.com/marsus/MyPatches/blob/master/ChannelVocoderPatch.hpp

blocksize is 128 samples, bandlength = (blocksize-2) / bands; q of buffering and overlap as our buffer at 32 samples is too small (512?)

see also: https://www.rebeltech.org/patch-library/patch/FFT_Through/

how we can narrow bands, move bands etc?

- phase vocoder?

- LPC swops, bends

// below not input based

- apply WORM speech filters
- throat/tube simulations
- beak and reflections
- other physical models
- apply extracted raven and other LPC co-efficients
- bandpass filters - mix and manipulate!
[- no transform - or have aux out anyways for no transform...]

* approaches and software

** wavetables

** vocoding

*** warps

- we made some progress - calcs for coeffs in filter_my.py but in warps is different sample rates/filters and decimation etc. for varying bandwidth (warps general samplerate is 96K)

main action in callback:  modulator.Process((ShortFrame*)input, (ShortFrame*)output, n);

formant shift and envelope actions...

** LPC

** raven/bird simulations

*** Mindlin

finch_void.c

*** Fletcher
*** Gardner
** glottal models/birds too so some crossover with above

*** LF (Liljen/Fant)

lfgen/lfgen2?

*** Klatt/KLSYN88/check nvp??

*** Rosenberg

http://homepage.univie.ac.at/christian.herbst//python/glottal_air_flow_models_8py_source.html = KLGLOTT88 and Rosenberg

now as *glottalair.py* and writing wav file - seems working -> port to C (also Rosenberg tests in lfgen.c are working)

http://www.mattmontag.com/projects-page/academic/speech

*** Titze

*** Herzel

*** Ishizaka and Flanagan

/root/projects/ERD_MODULES/RAVEN/older_notes_and_software/archived/IF_final.m

*** flowgen_shimmer in voice_synth in docs - Fant model WORKING

in lfgen2

*** praat

*** Software examples.

**** voicform?


** throat/tubes

*** APEX

*** tubes and ntubes SC code tube.c etc.

*** 1. Kelly-Lochbaum model: https://ccrma.stanford.edu/~jos/pasp/Singing_Kelly_Lochbaum_Vocal_Tract.html -> Perry Cook (refs/code? PRCThesis.pdf)

*** - elements BLOW to investigate: [[file:~/projects/ERD_modules/older/eurorack/elements/dsp/tube.cc::/%20Simple%20waveguide%20tube.][file:~/projects/ERD_modules/older/eurorack/elements/dsp/tube.cc::/ Simple waveguide tube.]] and exciter is quite simple?

** etc

*** wavetables

- others: wavetable, formants a la SINGER/SPASM with two glottal
  oscillators and vibrato -> where? check VOICFORM again, LPC

- plague model (where we find clean code? looking now at simforstacksansmem2.c

** older notes

*** what are the jacks and controls?

- two inputs with incoming volumes
- one output

2x or 3x x/y cv and knobs?

16x valueY eg for vocoder/throat

mode

speed/update speed - when far right then we use SPEED in which is TRIGGER IN 

or for vocoder x-channel z-parameter y-value [but maybe there are not so many parameters]

maybe graphic display as on o+c: OLED (but question there of SPI issues - so can use i2c OLED)

or we use 16x leds exposed under soldermask - but how we select which to show (on knob change but there could be multiple simultaneous changes)


* Mindlin email

https://github.com/zekearneodo/syrinxsynth

Dear Martin,

cool project! i´d love to follow your advances. And if some of my codes could be of any help,
please let me know. Also notice that in the webpage of my my lab there is some soft available for
downloading (www.lsd.df.uba.ar).

From the dynamics of the labia to the flow, one has to multiply the
average velocity of the air through the glottis and the transverse
glottal area, which is proportional to (constant-x). For a proxy of
the velocity you can the air sac pressure (as as a proxy for that, the
envelope of the sound you want to mimic). As a first approach, for
S(t) use the U(t) that you are generating. Then you can enrich the
sound by using a linear combination that includes U´. you wont be able
to fit parameters of a model from first principles.

Please feel free to contact me if you need any help.
And I would love to hear about your project!

cheers,

Gabo

On Mon, Sep 19, 2016 at 6:36 PM, <m@1010.co.uk> wrote:

    Dear Gabriel Mindlin,

    I'm an artist working with sound and electronics. I'm currently
    working on the artificial (software) synthesis of crow or raven
    calls and I've found your book and associated papers a fantastic
    and informative resource. I have almost no background in
    mathematics but with some help I'm working through the equations
    in the book as a first step towards the project. One point I'm
    having problems with is the coupling between source and vocal
    tract. I understand the reflections element but neither how to
    derive the time variations of flow (p.84 U(t)) from x, nor (p.91)
    exactly what the function within the pressure perturbation s(t)
    could be ( f(x,dx/dt) which depends on the kinematics of the
    labia.

    Apologies in advance if I missed something here and look forward
    to any help or answers you can offer!

    best wishes

    Martin Howse


* maybe easier just to comment on all code in archived

- also mari python experiments

* refs

https://github.com/zekearneodo/syrinxsynth

https://medium.com/@IckeIlknur/central-pattern-generators-to-synthesize-birdsongs-f0d09d6936c0
